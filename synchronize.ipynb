{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import scipy.io\n",
    "# import ntplib\n",
    "import datetime\n",
    "# from datetime import datetime, timezone, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = 1\n",
    "walk = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_video_subset(video_path, start_frame, end_frame, output_path):\n",
    "    \"\"\"\n",
    "    Extract a subset of frames from a video file while keeping a subset of the audio.\n",
    "\n",
    "    Parameters:\n",
    "        video_path (str): Path to the input video file.\n",
    "        start_frame (int): Starting frame index.\n",
    "        end_frame (int): Ending frame index.\n",
    "        output_path (str): Path to save the output video file.\n",
    "    \"\"\"\n",
    "    # Load video clip\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "\n",
    "    print(\"video_clip.fps:\", video_clip.fps)\n",
    "\n",
    "    # Extract audio\n",
    "    audio_clip = video_clip.audio\n",
    "\n",
    "    # Extract subset of audio\n",
    "    subset_audio_clip = audio_clip.subclip(start_frame / video_clip.fps, end_frame / video_clip.fps)\n",
    "\n",
    "    # Extract subset of frames\n",
    "    subset_clip = video_clip.subclip(start_frame / video_clip.fps, end_frame / video_clip.fps)\n",
    "\n",
    "    # Set audio for subset clip\n",
    "    subset_clip = subset_clip.set_audio(subset_audio_clip)\n",
    "\n",
    "    # Write video file with audio\n",
    "    subset_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\", logger=None)\n",
    "\n",
    "    # Close the video clip\n",
    "    video_clip.close()\n",
    "\n",
    "\n",
    "def extract_video_noaudio_subset(video_path, start_frame, end_frame, output_path):\n",
    "    \"\"\"\n",
    "    Extract a subset of frames from a video file without including audio.\n",
    "\n",
    "    Parameters:\n",
    "        video_path (str): Path to the input video file.\n",
    "        start_frame (int): Starting frame index.\n",
    "        end_frame (int): Ending frame index.\n",
    "        output_path (str): Path to save the output video file.\n",
    "    \"\"\"\n",
    "    # Load video clip\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "\n",
    "    # Extract subset of frames\n",
    "    subset_clip = video_clip.subclip(start_frame / video_clip.fps, end_frame / video_clip.fps)\n",
    "\n",
    "    # Write video file without audio\n",
    "    subset_clip.write_videofile(output_path, codec=\"libx264\", audio=False, logger=None)\n",
    "\n",
    "    # Close the video clip\n",
    "    video_clip.close()\n",
    "\n",
    "def extract_video_audio_subset(video_path, start_frame, end_frame, output_video_path, output_audio_path):\n",
    "    \"\"\"\n",
    "    Extract a subset of frames from a video file and save the video and audio separately.\n",
    "\n",
    "    Parameters:\n",
    "        video_path (str): Path to the input video file.\n",
    "        start_frame (int): Starting frame index.\n",
    "        end_frame (int): Ending frame index.\n",
    "        output_video_path (str): Path to save the output video file.\n",
    "        output_audio_path (str): Path to save the output audio file.\n",
    "    \"\"\"\n",
    "    # Validate input parameters\n",
    "    if not os.path.isfile(video_path):\n",
    "        raise FileNotFoundError(f\"Video file not found at {video_path}\")\n",
    "    if start_frame < 0 or end_frame < 0:\n",
    "        raise ValueError(\"Frame indices must be non-negative\")\n",
    "        # return \"Frame indices must be non-negative\"\n",
    "    if end_frame <= start_frame:\n",
    "        raise ValueError(\"End frame must be greater than start frame\")\n",
    "        # return \"End frame must be greater than start frame\"\n",
    "\n",
    "    # Load video clip\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "\n",
    "    # Extract subset of frames\n",
    "    subset_clip = video_clip.subclip(start_frame / video_clip.fps, end_frame / video_clip.fps)\n",
    "\n",
    "    # Write video file\n",
    "    subset_clip.write_videofile(output_video_path, codec=\"libx264\", logger=None)\n",
    "\n",
    "    # Close the video clip\n",
    "    subset_clip.close()\n",
    "\n",
    "    # Extract audio\n",
    "    audio_clip = video_clip.audio\n",
    "\n",
    "    # Calculate time in seconds for subclipping\n",
    "    start_time = start_frame / video_clip.fps\n",
    "    end_time = end_frame / video_clip.fps\n",
    "\n",
    "    # Extract subset of audio\n",
    "    subset_audio_clip = audio_clip.subclip(start_time, end_time)\n",
    "\n",
    "    # Write audio file\n",
    "    subset_audio_clip.write_audiofile(output_audio_path, logger=None)\n",
    "\n",
    "    # Close the audio clip\n",
    "    subset_audio_clip.close()\n",
    "\n",
    "    # Close the video clip\n",
    "    video_clip.close()\n",
    "\n",
    "\n",
    "def matlab_datenum_to_formatted_string(matlab_datenum):\n",
    "\n",
    "    # Convert MATLAB datenum to Python datenum by subtracting the MATLAB epoch\n",
    "    python_datenum = matlab_datenum\n",
    "\n",
    "    # Convert Python datenum to datetime\n",
    "    python_datetime = datetime.datetime.fromordinal(int(python_datenum)) + datetime.timedelta(days=python_datenum % 1) - datetime.timedelta(days=366)\n",
    "\n",
    "    # Format datetime string\n",
    "    formatted_string = python_datetime.strftime(\"%Y-%m-%d_%H-%M-%S-%f\")[:-3]\n",
    "\n",
    "    return formatted_string\n",
    "\n",
    "\n",
    "def calculate_duration(datetime_str1, datetime_str2):\n",
    "    \"\"\"\n",
    "    Calculate the duration between two datetime strings.\n",
    "\n",
    "    Parameters:\n",
    "        datetime_str1 (str): First datetime string.\n",
    "        datetime_str2 (str): Second datetime string.\n",
    "\n",
    "    Returns:\n",
    "        datetime.timedelta: Duration between the two datetime strings.\n",
    "    \"\"\"\n",
    "    # Convert the datetime strings to datetime objects\n",
    "    datetime_obj1 = datetime.datetime.strptime(datetime_str1, '%Y-%m-%d_%H-%M-%S-%f')\n",
    "    datetime_obj2 = datetime.datetime.strptime(datetime_str2, '%Y-%m-%d_%H-%M-%S-%f')\n",
    "\n",
    "    # Calculate the duration\n",
    "    duration = datetime_obj2 - datetime_obj1\n",
    "\n",
    "    # Return the duration\n",
    "    return duration\n",
    "\n",
    "\n",
    "def find_close_frame(time_label, time_data_array):\n",
    "\n",
    "    frame_index_data = 0\n",
    "    time_label_num = datetime.datetime.strptime(time_label, '%Y-%m-%d_%H-%M-%S-%f')\n",
    "\n",
    "    for temp_index in range(time_data_array.shape[0]):\n",
    "\n",
    "        temp_time_data = datetime.datetime.strptime(time_data_array[temp_index], '%Y-%m-%d_%H-%M-%S-%f')\n",
    "\n",
    "        if temp_time_data >= time_label_num:\n",
    "\n",
    "            frame_index_data = temp_index\n",
    "            # print(\"syncronze frame: \", frame_index_data, time_label, time_data_array[temp_index])\n",
    "            break\n",
    "\n",
    "    return frame_index_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fre_np = 250, fre_gopro = 60, fre_pupil = 60\n",
    "# Load all data and timestamp: Neural-Pace (NP) signal, GoPro videos, Pupil videos, Xsens, phone (acc, gyro, mag, GPS, light, audio)\n",
    "load_syncronized_folder = f'../../RW{subject}/RW{subject}-Walk{walk}-extracted/'\n",
    "save_syncronized_splt_folder = f'../../synchronized/RW{subject}/RW{subject}-Walk{walk}-self-syncronize-split/'\n",
    "\n",
    "if not os.path.exists(save_syncronized_splt_folder):\n",
    "    # Create the directory\n",
    "    os.makedirs(save_syncronized_splt_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106306,) (106306, 3)\n",
      "(53557,) (53557, 3)\n",
      "(51986,) (51986, 3)\n",
      "(3586,) (3586, 1)\n",
      "(138, 2) (138,)\n",
      "(94424, 3) (94424, 3)\n",
      "(48608,) (48608, 3)\n",
      "(49418,) (49418, 3)\n",
      "(151, 2) (151, 2)\n",
      "(130094,) (130094, 9) 2021-04-28_10-00-16-569 2021-04-28_10-21-57-509\n"
     ]
    }
   ],
   "source": [
    "# Event Description PupilFrame  GoProFrame  NPSample    NTP\n",
    "df = pd.read_csv(f'../../label_RWNApp_Output_Jan2024/evnts_RWNApp_RW{subject}_Walk{walk}.csv')\n",
    "label = df['Event']\n",
    "ntp_label = df['NTP']\n",
    "# PupilFrame = df['PupilFrame']\n",
    "GoProFrame = df['GoProFrame']\n",
    "NPSample = df['NPSample']\n",
    "\n",
    "# convert matlab NTP time to datetime timestamp\n",
    "time_label = [matlab_datenum_to_formatted_string(md) for md in ntp_label/60/60/24]\n",
    "# np.save(save_folder + \"time_label\", time_label)\n",
    "num_of_label = len(time_label)\n",
    "\n",
    "\n",
    "# Neural-Pace (NP) signal, GoPro videos, Pupil videos, Xsens, phone (acc, gyro, mag, GPS, light, audio)\n",
    "# fre_np = 250, fre_gopro = 60, fre_pupil = 60\n",
    "\n",
    "\n",
    "## load np data\n",
    "data_np = np.load(load_syncronized_folder + 'data_np.npy')\n",
    "time_np = np.load(load_syncronized_folder + 'time_np.npy')\n",
    "\n",
    "## load Gopro video\n",
    "data_gopro = load_syncronized_folder + 'data_video_gopro.mp4'\n",
    "time_gopro = np.load(load_syncronized_folder + 'time_gopro.npy')\n",
    "\n",
    "## load Pupil video\n",
    "data_pupil = load_syncronized_folder + 'data_video_pupil.mp4'\n",
    "time_pupil = np.load(load_syncronized_folder + 'time_pupil.npy')\n",
    "\n",
    "## load xsense data: only center of mass currently\n",
    "df_xsense = pd.read_csv(load_syncronized_folder + 'data_xs_Center-of-Mass.csv')\n",
    "time_xsense = np.load(load_syncronized_folder + 'time_xs.npy')\n",
    "# frame_xsense = df_xsense['Frame']\n",
    "data_xsense = df_xsense.iloc[:, 1:]\n",
    "\n",
    "## load all of chestphone data\n",
    "df = pd.read_csv(load_syncronized_folder + \"data_chest_phone_acc.csv\", header=None)\n",
    "time_chestphone_acc = df.iloc[:, 0]\n",
    "data_chestphone_acc = df.iloc[:, 1:]\n",
    "print(\"chest acc:\", time_chestphone_acc.shape, data_chestphone_acc.shape)\n",
    "\n",
    "df = pd.read_csv(load_syncronized_folder + \"data_chest_phone_gyro.csv\", header=None)\n",
    "time_chestphone_gyro = df.iloc[:, 0]\n",
    "data_chestphone_gyro = df.iloc[:, 1:]\n",
    "print(\"chest gyro:\", time_chestphone_gyro.shape, data_chestphone_gyro.shape)\n",
    "\n",
    "df = pd.read_csv(load_syncronized_folder + \"data_chest_phone_mag.csv\", header=None)\n",
    "time_chestphone_mag = df.iloc[:, 0]\n",
    "data_chestphone_mag = df.iloc[:, 1:]\n",
    "print(\"chest mag:\", time_chestphone_mag.shape, data_chestphone_mag.shape)\n",
    "\n",
    "df = pd.read_csv(load_syncronized_folder + \"data_chest_phone_light.csv\", header=None)\n",
    "time_chestphone_light = df.iloc[:, 0]\n",
    "data_chestphone_light = df.iloc[:, 1:]\n",
    "print(\"chest light:\", time_chestphone_light.shape, data_chestphone_light.shape)\n",
    "\n",
    "df = pd.read_csv(load_syncronized_folder + \"data_chest_phone_gps.csv\", header=None)\n",
    "time_chestphone_gps = df.iloc[:, 0]\n",
    "data_chestphone_gps_1 = df.iloc[:, 1].str.extract(r'Lat: (/d+/./d+)', expand=False)## delete the str of \"Lat:\"\n",
    "data_chestphone_gps_1 = np.array(data_chestphone_gps_1.astype(float))\n",
    "data_chestphone_gps_2 = df.iloc[:, 2].str.extract(r'Long: (-?/d+/./d+)', expand=False)## delete the str of \"Long:\"\n",
    "data_chestphone_gps_2 = np.array(data_chestphone_gps_2.astype(float))\n",
    "data_chestphone_gps = np.stack((data_chestphone_gps_1, data_chestphone_gps_2), axis=1)\n",
    "print(\"chest gps:\", data_chestphone_gps.shape, time_chestphone_gps.shape)\n",
    "\n",
    "\n",
    "## load all of pupilphone data\n",
    "df = pd.read_csv(load_syncronized_folder + \"data_pupil_phone_acc.csv\", header=None)\n",
    "time_pupilphone_acc = df.iloc[:, 0]\n",
    "data_pupilphone_acc = df.iloc[:, 1:]\n",
    "print(\"pupil acc:\", data_pupilphone_acc.shape, data_pupilphone_acc.shape)\n",
    "\n",
    "df = pd.read_csv(load_syncronized_folder + \"data_pupil_phone_gyro.csv\", header=None)\n",
    "time_pupilphone_gyro = df.iloc[:, 0]\n",
    "data_pupilphone_gyro = df.iloc[:, 1:]\n",
    "print(\"pupil gyro:\", time_pupilphone_gyro.shape, data_pupilphone_gyro.shape)\n",
    "\n",
    "df = pd.read_csv(load_syncronized_folder + \"data_pupil_phone_mag.csv\", header=None)\n",
    "time_pupilphone_mag = df.iloc[:, 0]\n",
    "data_pupilphone_mag = df.iloc[:, 1:]\n",
    "print(\"pupil mag:\", time_pupilphone_mag.shape, data_pupilphone_mag.shape)\n",
    "\n",
    "df = pd.read_csv(load_syncronized_folder + \"data_pupil_phone_gps.csv\", header=None)\n",
    "time_pupilphone_gps = df.iloc[:, 0]\n",
    "data_pupilphone_gps_1 = df.iloc[:, 1].str.extract(r'Lat: (/d+/./d+)', expand=False)## delete the str of \"Lat:\"\n",
    "data_pupilphone_gps_1 = np.array(data_pupilphone_gps_1.astype(float))\n",
    "data_pupilphone_gps_2 = df.iloc[:, 2].str.extract(r'Long: (-?/d+/./d+)', expand=False)## delete the str of \"Long:\"\n",
    "data_pupilphone_gps_2 = np.array(data_pupilphone_gps_2.astype(float))\n",
    "data_pupilphone_gps = np.stack((data_pupilphone_gps_1, data_pupilphone_gps_2), axis=1)\n",
    "print(\"pupil gps:\", data_pupilphone_gps.shape, data_pupilphone_gps.shape)\n",
    "\n",
    "print(\"xs:\", time_xsense.shape, data_xsense.shape, time_xsense[0], time_xsense[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Frames\n",
    "video_clip = VideoFileClip(data_gopro)\n",
    "# ntp_start_0 = ntp_label[0] - GoProFrame[0] / video_clip.fps\n",
    "# short_frames = [22]\n",
    "greped_index = {} # {greped_index: (greped_label, grep reason, time label)} indexs that got filtered\n",
    "label_total_time = {} # {label: datetime.timedelta} total time in one walk of each label\n",
    "label_missing_cnt = {} # {label: missing times}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling frequency:\n",
      "pupil_acc_sample_freq: 10000.0\n",
      "pupil_gps_sample_freq: 0.0\n",
      "pupil_gyro_sample_freq: 20000.0\n",
      "pupil_mag_sample_freq: 20000.0\n",
      "chest_acc_sample_freq: 10000.0\n",
      "chest_gps_sample_freq: 0.0\n",
      "chest_gyro_sample_freq: 19000.0\n",
      "chest_mag_sample_freq: 20000.0\n",
      "chest_light_sample_freq: 98000.0\n"
     ]
    }
   ],
   "source": [
    "def get_sampling_freq(time_series):\n",
    "    time_series = pd.to_datetime(time_series, format='%Y-%m-%d_%H-%M-%S-%f')\n",
    "    time_differences = time_series.diff()\n",
    "    time_differences = time_differences.dropna()\n",
    "    time_differences = time_differences.dt.total_seconds()*1e6\n",
    "    # print(time_differences)\n",
    "    sample_freq = time_differences.mode()\n",
    "    return sample_freq.iloc[0]\n",
    "\n",
    "\n",
    "pupil_acc_sample_freq = get_sampling_freq(time_pupilphone_acc)\n",
    "pupil_gps_sample_freq = get_sampling_freq(time_pupilphone_gps)\n",
    "pupil_gyro_sample_freq = get_sampling_freq(time_pupilphone_gyro)\n",
    "pupil_mag_sample_freq = get_sampling_freq(time_pupilphone_mag)\n",
    "chest_acc_sample_freq = get_sampling_freq(time_chestphone_acc)\n",
    "chest_gps_sample_freq = get_sampling_freq(time_chestphone_gps)\n",
    "chest_gyro_sample_freq = get_sampling_freq(time_chestphone_gyro)\n",
    "chest_mag_sample_freq = get_sampling_freq(time_chestphone_mag)\n",
    "chest_light_sample_freq = get_sampling_freq(time_chestphone_light)\n",
    "\n",
    "print(\"Sampling frequency:\")\n",
    "print(\"pupil_acc_sample_freq:\", pupil_acc_sample_freq)\n",
    "print(\"pupil_gps_sample_freq:\", pupil_gps_sample_freq) # The most frequent difference is 0.0 but not exactly. Manually set to 7 seconds\n",
    "print(\"pupil_gyro_sample_freq:\", pupil_gyro_sample_freq)\n",
    "print(\"pupil_mag_sample_freq:\", pupil_mag_sample_freq)\n",
    "print(\"chest_acc_sample_freq:\", chest_acc_sample_freq)\n",
    "print(\"chest_gps_sample_freq:\", chest_gps_sample_freq) # The most frequent difference is 0.0 but not exactly. Manually set to 7 seconds\n",
    "print(\"chest_gyro_sample_freq:\", chest_gyro_sample_freq)\n",
    "print(\"chest_mag_sample_freq:\", chest_mag_sample_freq)\n",
    "print(\"chest_light_sample_freq:\", chest_light_sample_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.typing import NDArray\n",
    "import datetime\n",
    "\n",
    "sample_freq_dict = {\n",
    "    'chestphone_gps': 7,\n",
    "    # 'chestphone_light': 1,\n",
    "    'pupilphone_gps': 7\n",
    "} #unit: second\n",
    "\n",
    "def calculate_time_diff(time_str1, time_str2):\n",
    "    '''Calculate the difference between time_str1 and time_str2. Both input times are str in format: '%Y-%m-%d_%H-%M-%S-%f' '''\n",
    "    time1 = datetime.datetime.strptime(time_str1, '%Y-%m-%d_%H-%M-%S-%f')\n",
    "    time2 = datetime.datetime.strptime(time_str2, '%Y-%m-%d_%H-%M-%S-%f')\n",
    "\n",
    "    return abs(time2 - time1).total_seconds()\n",
    "\n",
    "def extract_modalities(\n",
    "        start_frame_index : int,\n",
    "        end_frame_index : int,\n",
    "        time_arr : NDArray,\n",
    "        data_arr : NDArray,\n",
    "        event : str, # all events except for gopro. Gopro is processed outside this function.\n",
    "        extract_np : bool = True, # whether to extract and save the np file. Default is True. If setting to False, this function only returns whether the modality is missing or not.\n",
    "        time_label = time_label,\n",
    "        save_syncronized_splt_folder : str = save_syncronized_splt_folder,\n",
    "    ):\n",
    "    global label_missing_cnt, modalit_missing_time\n",
    "    start_frame = find_close_frame(time_label[start_frame_index], time_arr)\n",
    "    end_frame = find_close_frame(time_label[end_frame_index], time_arr)\n",
    "    dura = calculate_duration(time_label[start_frame_index], time_label[end_frame_index])\n",
    "\n",
    "    # print(\"time_{}: \".format(event), time_arr[start_frame], time_arr[end_frame], calculate_duration(time_arr[start_frame], time_arr[end_frame]))\n",
    "    \n",
    "    if event in ['chestphone_acc', 'chestphone_gyro', 'chestphone_mag', 'pupilphone_acc', 'pupilphone_gyro', 'pupilphone_mag', 'xs_CoM']:\n",
    "        if end_frame <= start_frame:\n",
    "            label_missing_cnt[event] = label_missing_cnt.get(event, 0) + 1\n",
    "            return False\n",
    "        else:\n",
    "            if extract_np:\n",
    "                output_path = save_syncronized_splt_folder + '{}_{}.npy'.format(start_frame_index, event)\n",
    "                np.save(output_path, data_arr[start_frame:end_frame])\n",
    "            return True\n",
    "    elif event in ['chestphone_gps', 'chestphone_light', 'pupilphone_gps']:\n",
    "        if end_frame <= start_frame:\n",
    "            if calculate_time_diff(time_label[start_frame_index], time_arr[start_frame]) > sample_freq_dict[event]:\n",
    "                label_missing_cnt[event] = label_missing_cnt.get(event, 0) + 1\n",
    "                return False\n",
    "            else:\n",
    "                end_frame += 1\n",
    "\n",
    "        # If end_frame > start_frame or time_diff <= sample_freq, return true\n",
    "        if extract_np:\n",
    "            output_path = save_syncronized_splt_folder + '{}_{}.npy'.format(start_frame_index, event)\n",
    "            np.save(output_path, data_arr[start_frame:end_frame])\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame  9 :\n",
      "label:  Doorway\n",
      "End frame index: 11\n",
      "time_label:  2021-04-28_10-04-39-424 2021-04-28_10-04-39-699 0:00:00.275000\n",
      "Frame  11 :\n",
      "label:  Choice Point\n",
      "End frame index: 12\n",
      "time_label:  2021-04-28_10-04-39-699 2021-04-28_10-04-39-966 0:00:00.267000\n",
      "Exception: 'chestphone_light'\n",
      "Frame  12 :\n",
      "label:  Correct Turn Beg\n",
      "End frame index: 14\n",
      "time_label:  2021-04-28_10-04-39-966 2021-04-28_10-04-42-593 0:00:02.627000\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "## Start at \"Walk Beg\"\n",
    "walk_beg_index = 0\n",
    "func_extract_label = lambda index : label[index][:-4] if (label[index].endswith(\"Beg\") or label[index].endswith(\"End\")) else label[index]\n",
    "while label[walk_beg_index] != \"Walk Beg\":\n",
    "    greped_index[walk_beg_index] = (func_extract_label(walk_beg_index), \"Event before Walk Beg\", time_label[walk_beg_index])\n",
    "    walk_beg_index += 1\n",
    "\n",
    "file_stats = save_syncronized_splt_folder + \"index_stats.csv\"\n",
    "\n",
    "with open(file_stats, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow([\"Index\", \"Label\", \"Duration\", \"Num of Modalities\", \"Missing Modalities\"])\n",
    "    \n",
    "    temp_index = walk_beg_index + 1\n",
    "    while temp_index < num_of_label:\n",
    "        ## End at \"Walk End\"\n",
    "        if label[temp_index] == \"Walk End\":\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            ## skip \"xxx End\" events\n",
    "            if label[temp_index].endswith(\"End\"):\n",
    "                continue\n",
    "            \n",
    "            start_frame_index = temp_index\n",
    "            end_frame_index = start_frame_index + 1\n",
    "\n",
    "            cut_label = func_extract_label(start_frame_index)\n",
    "\n",
    "            ## grep not interested labels\n",
    "            if cut_label not in [\"Doorway\", \"Talking\", \"Correct Turn\", \"Incorrect Turn\", \"Lost\", \"Stop\", \"Abnormal\", \"Pointing\", \"Outdoor\", \"Choice Point\", \"Stare\", \"New Context\"]:\n",
    "                greped_index[start_frame_index] = (cut_label, \"Not intereted event\", time_label[start_frame_index])\n",
    "                continue\n",
    "\n",
    "            ## Find end_frame_index\n",
    "            if label[start_frame_index].endswith(\"Beg\"):\n",
    "                while end_frame_index < num_of_label:\n",
    "                    if label[end_frame_index].endswith(\"End\") and func_extract_label(end_frame_index) == cut_label:\n",
    "                        break\n",
    "                    end_frame_index += 1\n",
    "                if end_frame_index >= num_of_label:\n",
    "                    raise ValueError(f\"Corresponding End event missing: {start_frame_index} {cut_label}\")\n",
    "            else: # merge successive identical label\n",
    "                while func_extract_label(end_frame_index) == cut_label and end_frame_index < num_of_label:\n",
    "                    end_frame_index += 1\n",
    "                temp_index = end_frame_index - 1 # align with the \"+1\" later\n",
    "            ########################\n",
    "\n",
    "            modality_num = 0\n",
    "            missing_modality = []\n",
    "            extract_np = True\n",
    "\n",
    "            print(\"Frame \", start_frame_index, \":\")\n",
    "            print(\"label: \", label[start_frame_index])\n",
    "            print(\"End frame index:\", end_frame_index)\n",
    "            # input(\"Press to continue......\")\n",
    "            print(\"time_label: \", time_label[start_frame_index], time_label[end_frame_index], calculate_duration(time_label[start_frame_index], time_label[end_frame_index]))\n",
    "\n",
    "            ############### grep invalid data. If one of gopro/pupil/np frame is missing, grep all data ###############\n",
    "            start_frame_gopro = GoProFrame[start_frame_index]\n",
    "            end_frame_gopro = GoProFrame[end_frame_index]\n",
    "            dura_gopro = calculate_duration(time_gopro[start_frame_gopro], time_gopro[end_frame_gopro])\n",
    "            # print(\"time_gopro: \", time_gopro[start_frame_gopro], time_gopro[end_frame_gopro], calculate_duration(time_gopro[start_frame_gopro], time_gopro[end_frame_gopro]))\n",
    "\n",
    "            if end_frame_gopro <= start_frame_gopro:\n",
    "                label_missing_cnt['gopro'] = label_missing_cnt.get('gopro', 0) + 1\n",
    "                greped_index[start_frame_index] = (cut_label, 'gopro', time_label[start_frame_index])\n",
    "                extract_np = False\n",
    "                # raise ValueError(\"End frame must be greater than start frame:gopro\")\n",
    "\n",
    "            ############### sample np signals ###############\n",
    "            start_frame_np = NPSample[start_frame_index]\n",
    "            end_frame_np = NPSample[end_frame_index]\n",
    "            # print(\"time_np: \", time_np[start_frame_np], time_np[end_frame_np-1], calculate_duration(time_np[start_frame_np], time_np[end_frame_np-1]), data_np[start_frame_np:end_frame_np].shape) # the extracted end_frame_np is started from 1, so need to subtract 1 when apply to time_np. data_np slice won't include end_frame_np. Other modalities don't have this problem.\n",
    "            if end_frame_np <= start_frame_np:\n",
    "                label_missing_cnt['np'] = label_missing_cnt.get('np', 0) + 1\n",
    "                greped_index[start_frame_index] = (cut_label, 'np', time_label[start_frame_index])\n",
    "                extract_np = False\n",
    "            else:\n",
    "                output_path = save_syncronized_splt_folder + '{}_np.npy'.format(start_frame_index)\n",
    "                np.save(output_path, data_np[start_frame_np:end_frame_np])\n",
    "                modality_num += 1\n",
    "\n",
    "            ############### sample gopro videos ###############\n",
    "            if extract_np:\n",
    "                output_path = save_syncronized_splt_folder + '{}_gopro.mp4'.format(start_frame_index)\n",
    "                output_path_audio = save_syncronized_splt_folder + '{}_gopro_audio.wav'.format(start_frame_index)\n",
    "                extract_video_audio_subset(data_gopro, start_frame_gopro, end_frame_gopro, output_path, output_path_audio)\n",
    "                modality_num += 2 # will extract two modalities\n",
    "            \n",
    "                output_path = save_syncronized_splt_folder + '{}_pupil.mp4'.format(start_frame_index)\n",
    "                extract_video_noaudio_subset(data_pupil, start_frame_gopro, end_frame_gopro, output_path)\n",
    "                modality_num += 1\n",
    "\n",
    "            ############### sample other data ###############\n",
    "            if extract_modalities(start_frame_index, end_frame_index, time_chestphone_acc, data_chestphone_acc, event='chestphone_acc', extract_np=extract_np):\n",
    "                modality_num += 1\n",
    "            else:\n",
    "                missing_modality.append('chestphone_acc')\n",
    "            \n",
    "            if extract_modalities(start_frame_index, end_frame_index, time_chestphone_gyro, data_chestphone_gyro, event='chestphone_gyro', extract_np=extract_np):\n",
    "                modality_num += 1\n",
    "            else:\n",
    "                missing_modality.append('chestphone_gyro')\n",
    "            \n",
    "            if extract_modalities(start_frame_index, end_frame_index, time_chestphone_mag, data_chestphone_mag, event='chestphone_mag', extract_np=extract_np):\n",
    "                modality_num += 1\n",
    "            else:\n",
    "                missing_modality.append('chestphone_mag')\n",
    "            \n",
    "            if extract_modalities(start_frame_index, end_frame_index, time_chestphone_gps, data_chestphone_gps, event='chestphone_gps', extract_np=extract_np):\n",
    "                modality_num += 1\n",
    "            else:\n",
    "                missing_modality.append('chestphone_gps')\n",
    "            \n",
    "            if extract_modalities(start_frame_index, end_frame_index, time_chestphone_light, data_chestphone_light, event='chestphone_light', extract_np=extract_np):\n",
    "                modality_num += 1\n",
    "            else:\n",
    "                missing_modality.append('chestphone_light')\n",
    "            \n",
    "            if extract_modalities(start_frame_index, end_frame_index, time_pupilphone_acc, data_pupilphone_acc, event='pupilphone_acc', extract_np=extract_np):\n",
    "                modality_num += 1\n",
    "            else:\n",
    "                missing_modality.append('pupilphone_acc')\n",
    "            \n",
    "            if extract_modalities(start_frame_index, end_frame_index, time_pupilphone_gyro, data_pupilphone_gyro, event='pupilphone_gyro', extract_np=extract_np):\n",
    "                modality_num += 1\n",
    "            else:\n",
    "                missing_modality.append('pupilphone_gyro')\n",
    "            \n",
    "            if extract_modalities(start_frame_index,  end_frame_index, time_pupilphone_mag, data_pupilphone_mag, event='pupilphone_mag', extract_np=extract_np):\n",
    "                modality_num += 1\n",
    "            else:\n",
    "                missing_modality.append('pupilphone_mag')\n",
    "            \n",
    "            if extract_modalities(start_frame_index, end_frame_index, time_pupilphone_gps, data_pupilphone_gps, event='pupilphone_gps', extract_np=extract_np):\n",
    "                modality_num += 1\n",
    "            else:\n",
    "                missing_modality.append('pupilphone_gps')\n",
    "            \n",
    "            if extract_modalities(start_frame_index, end_frame_index, time_xsense, data_xsense, event='xs_CoM', extract_np=extract_np):\n",
    "                modality_num += 1\n",
    "            else:\n",
    "                missing_modality.append('xs_CoM')\n",
    "\n",
    "            ############### record label time ###############\n",
    "            if extract_np:\n",
    "                dura = calculate_duration(time_label[start_frame_index], time_label[end_frame_index])\n",
    "                label_total_time[cut_label] = label_total_time.get(cut_label, datetime.timedelta()) + dura\n",
    "                writer.writerow([start_frame_index, cut_label, dura, modality_num, \", \".join(missing_modality)])\n",
    "        \n",
    "        # except ValueError as e:\n",
    "        #     error_message = str(e)\n",
    "        #     if \"End frame must be greater than start frame\" in error_message:\n",
    "        #         # Extracting the event value\n",
    "        #         event = error_message.split(\":\")[1]\n",
    "        #         ############### record greped index ###############\n",
    "        #         greped_index[start_frame_index] = (cut_label, event, time_label[start_frame_index])\n",
    "        #     else:\n",
    "        #         greped_index[start_frame_index] = (cut_label, str(e), time_label[start_frame_index])\n",
    "        #     print(\"Exception:\", str(e))\n",
    "            \n",
    "        except Exception as e:\n",
    "            greped_index[start_frame_index] = (cut_label, str(e), time_label[start_frame_index])\n",
    "            print(\"Exception:\", str(e))\n",
    "        finally:\n",
    "            temp_index += 1\n",
    "\n",
    "assert (temp_index == num_of_label or label[temp_index] == \"Walk End\"), f\"Unexpected exit: temp_index={temp_index}\"\n",
    "for i in range(temp_index, num_of_label):\n",
    "    greped_index[i] = (func_extract_label(i), \"Event after Walk End\", time_label[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing counts of missing label......\n",
      "Counts of missing labels have been saved to ../../synchronized_test/RW1/RW1-Walk1-self-syncronize-split/missing_label_cnt.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# write index label map, greped index and label total time into .csv file\n",
    "file_label_time = save_syncronized_splt_folder + \"cal_label_time.csv\"\n",
    "file_greped = save_syncronized_splt_folder + \"greped_index.csv\"\n",
    "file_miss = save_syncronized_splt_folder + \"missing_label_cnt.csv\"\n",
    "\n",
    "# Writing the dictionary to a CSV file with multiple columns\n",
    "\n",
    "print(\"Writing total time of each label......\")\n",
    "with open(file_label_time, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['Label', 'Total Time in Walk'])\n",
    "    # Write the dictionary entries\n",
    "    for i_label, i_time in label_total_time.items():\n",
    "        writer.writerow([i_label, str(i_time)])\n",
    "print(f\"Total time of each label has been saved to {file_label_time}\")\n",
    "\n",
    "print(\"Writing greped label......\")\n",
    "with open(file_greped, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['Index', 'Label', 'Grep Reason', 'Time Label'])\n",
    "    # Write the dictionary entries\n",
    "    for index, value in greped_index.items():\n",
    "        i_label, reason, time_label = value\n",
    "        writer.writerow([index, i_label, reason, time_label])\n",
    "print(f\"Greped label has been saved to {file_greped}\")\n",
    "\n",
    "print(\"Writing counts of label......\")\n",
    "with open(file_miss, mode='w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    # Write the header row\n",
    "    writer.writerow(['Modality', 'Missing Count'])\n",
    "    # Write the dictionary entries\n",
    "    for i_label, cnt in label_missing_cnt.items():\n",
    "        writer.writerow([i_label, cnt])\n",
    "print(f\"Counts of missing labels have been saved to {file_miss}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
